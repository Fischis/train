Notebook for finetuning an LLama (7b) model on a vast.ai instance.
Configuration e.g.
- standard pytorch image
- RTX 4090 (24GB)
- HD: > 20GB 
- CPU/RAM: neglectable (any chice is fine)

Inspired by the colab version of https://www.youtube.com/watch?v=LSoqyynKU9E & https://github.com/tloen/alpaca-lora.git
